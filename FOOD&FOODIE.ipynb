{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1a3c52c",
   "metadata": {},
   "source": [
    "# <h1><center>Sentiment Analysis for Foody&Fooodie<h1><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e2b62a",
   "metadata": {},
   "source": [
    "## Business Understanding\n",
    "\n",
    "### Overview\n",
    "Foody&Foodie are a family run restaurant in San francisco, CA. As a veteran in the food business they understand that they will need to keep track of sentiments from their customer base to maintain a competitive edge in the market.\n",
    "\n",
    "### Problem Statement\n",
    "The management of Foody&Foodie understand the need to find reliable feedback to guide their decision-making aiming to improve their business and match their markets ever changing needs. \n",
    "\n",
    "\n",
    "### Challenges\n",
    "Within the Food industry, they're several measurable parameters to that determine the success of a restaurant and we must find a neutral data set where all these aspects can be fairly evaluated for an accurate result.\n",
    "\n",
    "### Proposed solution\n",
    "We will need to create a model to analyze customer sentiments through reviews on restaurants within the target area using a single popular review site, Yelp, to pull the relevant data as it is the most comprehensive compilation of reviews in the target market.\n",
    "\n",
    "\n",
    "\n",
    "### Objectives\n",
    "#### Main Objective\n",
    "- To create a model that could successfully predict the sentiment of a customerâ€™s review. The model would attain a recall score and accuracy score above 80%\n",
    "\n",
    "#### Specific Objective\n",
    "- To identify the most common words used in the dataset using a Word cloud.\n",
    "- To confirm the most common words that are positively and negatively tagged.\n",
    "- To recognize the products that have been opined by the customers.\n",
    "- To spot the distribution of the sentiments.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1ceffe",
   "metadata": {},
   "source": [
    "\n",
    "## Data Understanding\n",
    "Our dataset is a compilation of writen reviews, ratings, review IDs, review date and business IDs from the Yelp website. The compilation of this data allows us to clearly identfy positive and negatve sentiments in relation to a rating given on a scale of 1-5 as well as reactions to the sentiment by readers categorized as cool, useful or funny. \n",
    "Post cleaning the data, these are the metrics we will use to isolate and model a collective non biased scale of opinions on restarunts in the area.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "934de1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e42ecd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load restaurant data - This also works\n",
    "df = pd.read_csv(\"data.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1097c48a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iBUJvIOkToh2ZECVNq5PDg</td>\n",
       "      <td>iAD32p6h32eKDVxsPHSRHA</td>\n",
       "      <td>YB26JvvGS2LgkxEKOObSAw</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I've been eating at this restaurant for over 5...</td>\n",
       "      <td>2021-01-08 01:49:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HgEofz6qEQqKYPT7YLA34w</td>\n",
       "      <td>rYvWv-Ny16b1lMcw1IP7JQ</td>\n",
       "      <td>jfIwOEXcVRyhZjM4ISOh4g</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>How does a delivery person from here get lost ...</td>\n",
       "      <td>2021-01-02 00:19:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kxo5d6EOnOE-vERwQf2a1w</td>\n",
       "      <td>2ntnbUia9Bna62W0fqNcxg</td>\n",
       "      <td>S-VD26LE_LeJNx5nASk_pw</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The service is always good, the employees are ...</td>\n",
       "      <td>2021-01-26 18:01:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STqHwh6xd05bgS6FoAgRqw</td>\n",
       "      <td>j4qNLF-VNRF2DwBkUENW-w</td>\n",
       "      <td>yE1raqkLX7OZsjmX3qKIKg</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>two words: whipped. feta. \\nexplosion of amazi...</td>\n",
       "      <td>2021-01-27 23:28:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u0smrr16uVQ8pgSEseXcKg</td>\n",
       "      <td>H3P9EB7J9HP6PzkVjgFiOg</td>\n",
       "      <td>oQ5CPRt0R3AzFvcjNOqB1w</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>So day 2 in Nashville. I gotta get some BBQ. M...</td>\n",
       "      <td>2021-03-17 20:09:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  iBUJvIOkToh2ZECVNq5PDg  iAD32p6h32eKDVxsPHSRHA  YB26JvvGS2LgkxEKOObSAw   \n",
       "1  HgEofz6qEQqKYPT7YLA34w  rYvWv-Ny16b1lMcw1IP7JQ  jfIwOEXcVRyhZjM4ISOh4g   \n",
       "2  Kxo5d6EOnOE-vERwQf2a1w  2ntnbUia9Bna62W0fqNcxg  S-VD26LE_LeJNx5nASk_pw   \n",
       "3  STqHwh6xd05bgS6FoAgRqw  j4qNLF-VNRF2DwBkUENW-w  yE1raqkLX7OZsjmX3qKIKg   \n",
       "4  u0smrr16uVQ8pgSEseXcKg  H3P9EB7J9HP6PzkVjgFiOg  oQ5CPRt0R3AzFvcjNOqB1w   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0      5       0      0     0   \n",
       "1      1       0      0     0   \n",
       "2      5       0      0     0   \n",
       "3      5       0      0     0   \n",
       "4      5       0      0     0   \n",
       "\n",
       "                                                text                 date  \n",
       "0  I've been eating at this restaurant for over 5...  2021-01-08 01:49:36  \n",
       "1  How does a delivery person from here get lost ...  2021-01-02 00:19:00  \n",
       "2  The service is always good, the employees are ...  2021-01-26 18:01:45  \n",
       "3  two words: whipped. feta. \\nexplosion of amazi...  2021-01-27 23:28:03  \n",
       "4  So day 2 in Nashville. I gotta get some BBQ. M...  2021-03-17 20:09:00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ff19f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelevant columns\n",
    "df = df.drop(columns=['review_id', 'user_id', 'business_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b017a667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['stars', 'useful', 'funny', 'cool', 'text', 'date'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6020f1a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>429771.000000</td>\n",
       "      <td>429771.000000</td>\n",
       "      <td>429771.000000</td>\n",
       "      <td>429771.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.820449</td>\n",
       "      <td>0.822806</td>\n",
       "      <td>0.212450</td>\n",
       "      <td>0.487885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.513978</td>\n",
       "      <td>2.818655</td>\n",
       "      <td>1.231838</td>\n",
       "      <td>2.382432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>261.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>164.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               stars         useful          funny           cool\n",
       "count  429771.000000  429771.000000  429771.000000  429771.000000\n",
       "mean        3.820449       0.822806       0.212450       0.487885\n",
       "std         1.513978       2.818655       1.231838       2.382432\n",
       "min         1.000000       0.000000       0.000000       0.000000\n",
       "25%         3.000000       0.000000       0.000000       0.000000\n",
       "50%         5.000000       0.000000       0.000000       0.000000\n",
       "75%         5.000000       1.000000       0.000000       0.000000\n",
       "max         5.000000     261.000000     101.000000     164.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ab6dc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicates rows\n",
    "df.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3594cd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad055aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all text to lowercase\n",
    "df['text'] = df['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48540737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "df['text'] = df['text'].apply(lambda x: re.sub(f\"[{string.punctuation}]\", \"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff0b5ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove numbers\n",
    "df['text'] = df['text'].apply(lambda x: re.sub(r'\\d+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "581f978c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Remove stopwords\n",
    "df['text'] = df['text'].apply(lambda x: ' '.join([word for word in word_tokenize(x) if word not in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef5f6d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Initialize the WordNet lemmatizer\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Apply lemmatization\n",
    "df['text'] = df['text'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in word_tokenize(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfda0040",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'C:\\Users\\kerub\\Documents\\Moringa\\Sentiment-Analysis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mkerub\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMoringa\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSentiment-Analysis\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mrestaurant_reviews.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Save the cleaned data, overwriting the original file\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(file_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCleaned data has been saved and overwritten the existing file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\ANAC\\Lib\\site-packages\\pandas\\core\\generic.py:3772\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3761\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3763\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3764\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3765\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3769\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3770\u001b[0m )\n\u001b[1;32m-> 3772\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[0;32m   3773\u001b[0m     path_or_buf,\n\u001b[0;32m   3774\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   3775\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[0;32m   3776\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   3777\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   3778\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   3779\u001b[0m     quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[0;32m   3780\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   3781\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m   3782\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   3783\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m   3784\u001b[0m     quotechar\u001b[38;5;241m=\u001b[39mquotechar,\n\u001b[0;32m   3785\u001b[0m     date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[0;32m   3786\u001b[0m     doublequote\u001b[38;5;241m=\u001b[39mdoublequote,\n\u001b[0;32m   3787\u001b[0m     escapechar\u001b[38;5;241m=\u001b[39mescapechar,\n\u001b[0;32m   3788\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   3789\u001b[0m )\n",
      "File \u001b[1;32m~\\ANAC\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1186\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1165\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1167\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1168\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1169\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1184\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1185\u001b[0m )\n\u001b[1;32m-> 1186\u001b[0m csv_formatter\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1189\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\ANAC\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:240\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 240\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    243\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    244\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,\n\u001b[0;32m    245\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression,\n\u001b[0;32m    246\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options,\n\u001b[0;32m    247\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    250\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    251\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    256\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    257\u001b[0m     )\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\ANAC\\Lib\\site-packages\\pandas\\io\\common.py:737\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[1;32m--> 737\u001b[0m     check_parent_directory(\u001b[38;5;28mstr\u001b[39m(handle))\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[0;32m    740\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    741\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32m~\\ANAC\\Lib\\site-packages\\pandas\\io\\common.py:600\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    598\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m--> 600\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'C:\\Users\\kerub\\Documents\\Moringa\\Sentiment-Analysis'"
     ]
    }
   ],
   "source": [
    "# Path to the existing file\n",
    "file_path = r'C:\\Users\\kerub\\Documents\\Moringa\\Sentiment-Analysis\\restaurant_reviews.txt'\n",
    "\n",
    "# Save the cleaned data, overwriting the original file\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "print(f\"Cleaned data has been saved and overwritten the existing file: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1363d89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the cleaned dataset\n",
    "# Path to the CSV file\n",
    "file_path = r'C:\\Users\\kerub\\Documents\\Moringa\\Sentiment-Analysis\\restaurant_reviews.txt'\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\kerub\\Documents\\Moringa\\Sentiment-Analysis\\restaurant_reviews.txt')\n",
    "\n",
    "# Display the first five rows\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5530be",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA) ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36543544",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling missing values\n",
    "\n",
    " # Convert non-string values to strings, filling NaNs with an empty string\n",
    "df['text'] = df['text'].fillna('').astype(str)\n",
    "\n",
    "# Calculate the length of each text entry\n",
    "df['text_Length'] = df['text'].apply(len)\n",
    "\n",
    "# Display summary statistics of the text lengths\n",
    "print(df['text_Length'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9bb37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for basic information about the data\n",
    "df.info()\n",
    "\n",
    "# Summary statistics of the text lengths\n",
    "df['text_Length'] = df['text'].apply(len)\n",
    "df['text_Length'].describe()\n",
    "\n",
    "# Check for the distribution of sentiment labels (if available)\n",
    "if 'Sentiment' in df.columns:\n",
    "    print(df['Sentiment'].value_counts())\n",
    "    sns.countplot(x='Sentiment', data=df)\n",
    "    plt.title('Distribution of Sentiments')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49245afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a word cloud for the entire dataset\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "all_reviews = ' '.join(df['text'])\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_reviews)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud of All Reviews')\n",
    "plt.show()\n",
    "\n",
    "# Generate separate word clouds for positive and negative sentiments if labeled\n",
    "if 'Sentiment' in df.columns:\n",
    "    positive_reviews = ' '.join(df[df['Sentiment'] == 'positive']['Review'])\n",
    "    negative_reviews = ' '.join(df[df['Sentiment'] == 'negative']['Review'])\n",
    "    \n",
    "    # Positive reviews word cloud\n",
    "    wordcloud_positive = WordCloud(width=800, height=400, background_color='white').generate(positive_reviews)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud_positive, interpolation=\"bilinear\")\n",
    "    plt.axis('off')\n",
    "    plt.title('Word Cloud of Positive Reviews')\n",
    "    plt.show()\n",
    "    \n",
    "    # Negative reviews word cloud\n",
    "    wordcloud_negative = WordCloud(width=800, height=400, background_color='white').generate(negative_reviews)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud_negative, interpolation=\"bilinear\")\n",
    "    plt.axis('off')\n",
    "    plt.title('Word Cloud of Negative Reviews')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f0813d",
   "metadata": {},
   "source": [
    "### Distribution of Review Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d795be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of review lengths\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df['text_Length'], bins=50, kde=True)\n",
    "plt.title('Distribution of Text Lengths')\n",
    "plt.xlabel('Length of text')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11945b17",
   "metadata": {},
   "source": [
    "The majority of short reviews suggest users prefer brief comments, suggesting businesses should focus on concise messaging. The content may include quick impressions or detailed experiences, offering insights into customer satisfaction. Data analysis should consider skewness and median word count."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4591c40",
   "metadata": {},
   "source": [
    "#### Distribution of Star Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc66a31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot for the distribution of star ratings\n",
    "sns.countplot(x='stars', data=df)\n",
    "plt.title('Distribution of Star Ratings')\n",
    "plt.xlabel('Star Ratings')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9903eee0",
   "metadata": {},
   "source": [
    "The high number of 5-star reviews on Yelp may make it challenging to distinguish outstanding businesses from average ones due to the skewed nature of ratings. Additionally, Yelp reviewers may be more motivated to leave a review after a positive experience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88aa5faa",
   "metadata": {},
   "source": [
    "#### Distribution of \"Cool\", \"Useful\", and \"Funny\" Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49a755c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot for cool, useful, and funny votes\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=df[['cool', 'useful', 'funny']])\n",
    "plt.title('Distribution of Cool, Useful, and Funny Votes')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e59f1cc",
   "metadata": {},
   "source": [
    "The presence of numerous outliers in all three plots indicates that while most reviews receive a standard level of engagement, some stand out and generate significantly more reactions. This could be due to the content, business popularity, or timing of the review. The variation in IQRs and outliers suggests that some reviews resonate more strongly with the Yelp community, leading to higher interaction levels. Some reviews, particularly in the middle plot, have the potential to go viral on the Yelp platform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4373932",
   "metadata": {},
   "source": [
    " ### Top Most Frequent Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a116136",
   "metadata": {},
   "source": [
    "Lets dentify the most frequent words that can help understand common themes in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db431134",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Tokenize the reviews and remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['Tokens'] = df['text'].apply(lambda x: [word for word in word_tokenize(x.lower()) if word.isalnum() and word not in stop_words])\n",
    "\n",
    "# Flatten the list of tokens\n",
    "all_words = [word for tokens in df['Tokens'] for word in tokens]\n",
    "\n",
    "# Get the frequency distribution of words\n",
    "word_freq = Counter(all_words)\n",
    "\n",
    "# Plot the top N most frequent words\n",
    "top_n = 20\n",
    "common_words = word_freq.most_common(top_n)\n",
    "words, counts = zip(*common_words)\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "df_plot = pd.DataFrame({'Word': words, 'Frequency': counts})\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x='Frequency', y='Word', data=df_plot)\n",
    "plt.title(f'Top {top_n} Most Frequent Words')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Words')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ffb23d",
   "metadata": {},
   "source": [
    "The majority of reviews express positive sentiments, indicating customer satisfaction at restaurants. Key positive keywords focus on food quality and customer service, indicating their importance. Negative sentiments suggest areas for improvement, such as specific menu items or service speed. The diverse reviews highlight the importance of consistency in quality and service, highlighting the varied experiences of customers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9801d6e7",
   "metadata": {},
   "source": [
    "### Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff33843",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df.select_dtypes(include=['number']).shape[1] > 0:  \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
    "    plt.title('Correlation Matrix')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f010354f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
